{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing\n",
    "\n",
    "The developed classes need some thorough testing before we run the whole experiment. It would be very bad if the script breaks in the middle of tuning. This notebook lists some situations that should be tested and explains how to do so.\n",
    "\n",
    "The tests can be performed by evaluating the objective function for a specified set of parameter values. Every class has a method <i>objfunction</i>, which takes a list of values as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('..')\n",
    "import helpers\n",
    "import models\n",
    "from models import OneShotCNN, OneShotTransferCNN, OneShotAutoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize with logging and verbose\n",
    "model = OneShotCNN(log=True, verbose=1)\n",
    "# choose lower bound of model as example (THIS SHOULD BE DONE MANUALLY TO PERFORM THE TESTS)\n",
    "x = model.xlow\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, x is just a list of numbers. This can be put in the objective function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# test for given x\n",
    "model.objfunction(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The <i>hyper_map</i> attribute of the model can be used to get the index of a hyperparameter in X. For example, the learning rate is the first entry of X (index 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.hyper_map['learning_rate']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to see the full list of available hyperparameters (and their order), you can print the <i>hyperparams</i> attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.hyperparams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OneShotCNN tests\n",
    "\n",
    "For the simplest class, the OneShotCNN class, we should test the following:\n",
    "- The early stopping procedure in combination with logging. Do this by training a very bad model (setting RMSProp's learning rate to 0.1 should do the trick) and have log=True on initialization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = OneShotCNN(log=True, verbose=0)\n",
    "x = test.xlow\n",
    "x[test.hyper_map['learning_rate']] = 0.000000000001\n",
    "test.objfunction(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Works as intended"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OneShotTransferCNN tests\n",
    "\n",
    "For the simplest class, the OneShotCNN class, we should test the following:\n",
    "- The early stopping procedure in combination with logging. Do this by training a very bad model (setting RMSProp's learning rate to 0.1 should do the trick) and have log=True on initialization.\n",
    "- Having 'num_fixed_layers' larger than the total number of layers in the model.\n",
    "- .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transfermodel = OneShotTransferCNN(log=True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = transfermodel.xlow\n",
    "# set learning rates to too very bad values\n",
    "x[0] = 0.001 # big enough to learn nothing\n",
    "x[1] = 0.001 # don't let it learn much in fine tuning\n",
    "# set fixed layers to value bigger than the total number of layers\n",
    "x[transfermodel.hyper_map['num_fixed_layers']] = 9\n",
    "x[transfermodel.hyper_map['epochs']] = 1\n",
    "x[transfermodel.hyper_map['finetune_epochs']] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transfermodel.objfunction(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Outcomes\n",
    "- Early stopping works as intended and logging is not affected by it.\n",
    "- The big number of fixed layers results in the classifying layer also being fixed. This way, no fine tuning occurs. <strong>Problem fixed at March 6, 2018.</strong>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OneShotAutoencoder tests\n",
    "\n",
    "For the autoencoder class\n",
    "- General objective evaulation\n",
    "- Tuning procedure\n",
    "- Whether weights are frozen and reinitialized properly\n",
    "- Positioning of max pools and upsampling layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oneshotAE = OneShotAutoencoder(log=True, folds=3, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#oneshotAE.objfunction(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oneshotAE.tune_with_HORD(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Outcomes\n",
    "- Objective evaluation works\n",
    "- Tuning works\n",
    "- Freezing layers works properly for the case when all layers should be frozen except the classifier. <strong>Other values need more testing</strong>\n",
    "- Max pools and upsampling layers seem to position just fine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
